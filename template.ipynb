{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "# import dataset\n",
    "from classes.loaddata import OurDataset\n",
    "# import np\n",
    "import numpy as np\n",
    "# import torch\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# import pickle\n",
    "import pickle\n",
    "# image processer\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convolutional Neural Network\n",
    "\"\"\"\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channel = 3, num_classes = 200):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set hyperparameters\n",
    "\"\"\"\n",
    "# Hyperparameters\n",
    "input_size = 32\n",
    "num_classes = 200\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image transformations here:\n",
    "transformations that are necessary: \n",
    "- transforms.lambda since some have 1 input channel instead of 3\n",
    "- to tensor as a format\n",
    "\"\"\"\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: Image.fromarray(img) if isinstance(img, np.ndarray) else img),  \n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.Lambda(lambda img: img.convert('RGB')),  \n",
    "    transforms.ToTensor()  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If we have an Nvidia GPU, use it!\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading in all data using the dataset class in loaddata.py\n",
    "\"\"\"\n",
    "# initialize dataset\n",
    "train_dataset = OurDataset(csv_file = \"datafile/train_images.csv\", root_dir = \"datafile/train_images\", transform = my_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_dataset = OurDataset(csv_file = \"datafile/train_images.csv\", root_dir = \"datafile/test_images\", transform = my_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers=4)\n",
    "\n",
    "class_dictionary = np.load(\"datafile/class_names.npy\", allow_pickle=True).item()\n",
    "class_names = list(class_dictionary.keys())\n",
    "class_names = [name.split('.',1)[1] for name in class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instantiate model\n",
    "\"\"\"\n",
    "model = CNN().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking accuracy\n",
    "*Note: only working for traindata only so far\n",
    "\"\"\"\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # dont use gradient to check cause we dont need it here\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            y = y - 1\n",
    "            scores = model(x)\n",
    "            # find index for second dimension?\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum().item()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        print(f\"got {num_correct} / {num_samples} with accuracy {(float(num_correct)/float(num_samples))*100:.2f}\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run\n",
    "\n",
    "todo: save model\n",
    "\n",
    "*warning: long runtimes\n",
    "\"\"\"\n",
    "# Train network\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"epoch nr. {epoch}\")\n",
    "    # data: image, target: label for each image\n",
    "    for batch_index, (data, targets) in enumerate(train_loader):\n",
    "        # to cuda if possible else cpu\n",
    "        data = data.to(device=device)\n",
    "        targets=targets.to(device=device)\n",
    "\n",
    "        # print(data.shape)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_function(scores, targets - 1)\n",
    "\n",
    "        # backward\n",
    "        # set to zero from previous forward props\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "    # check accuracy\n",
    "    check_accuracy(train_loader, model)\n",
    "    # check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
